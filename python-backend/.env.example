# Buddhist RAG Application Configuration
# Copy this file to .env and configure your settings

# Model Provider Selection
# Options: local, openai, anthropic, google
MODEL_PROVIDER=local

# Enable fallback to local model if API fails
ENABLE_FALLBACK=true

# Local Model Settings (Ollama)
LOCAL_MODEL_NAME=qwen2.5:14b
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI Configuration
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_BASE_URL=  # Optional: custom endpoint

# Anthropic Configuration
# Get your API key from https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Google AI Configuration
# Get your API key from https://ai.google.dev/
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_MODEL=gemini-pro

# Model Parameters
MAX_CONTEXT_LENGTH=32768
MAX_RESPONSE_LENGTH=2048
TEMPERATURE=0.3
TOP_P=0.9

# Usage and Safety Settings
WARN_ON_API_USAGE=true
MAX_DAILY_API_CALLS=100

# Privacy Settings
# Set to true to allow data transmission to API providers
ALLOW_DATA_TRANSMISSION=false